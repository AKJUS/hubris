# HubrOS thoughts for my own self

*I wrote this document for my own reference, so it's probably not the best place
to start -- but here was my thought process for RFD41 if you're curious.*

I think we want a wee-but-not-minimal kernel, becuase minimality is one of those
engineering strange attractors.

Yes:

- Tasking
- Message passing (at least register-set-size, possibly bigger). Synchronous
  call-response. Maybe async as a bolt-on.
- Uniform interface to kernel and user abstractions (i.e. anything implemented
  in the kernel should be accessed by messages).
- Memory protection for tasks.
- Interrupt routing to tasks.

No:

- hard real time (so priority inheritance is OK)
- dynamic resource allocation?
- pure capability architecture

Maybe:

- Messages use object IDs as targets, so they're trivially forged; use a MAC
  layer / filter to determine who can talk to who

Open questions

- Do messages go through ports, or do we send messages to tasks directly? If we
  send messages to tasks directly, how do we control tasks?
- We need some kind of bulk memory-to-memory copy operation in the kernel. Is
  this connected to messaging or separate?

---

# Messaging sketch

Caller provides data and names target. Data includes an operation selector.

Caller is placed in "reply" state which records the target ID.

Recipient receives data and (unforgeable) sender identifier. Works out what to
do, replies. Reply succeeds because caller is in reply state with proper ID.

Messages are held in registers. Easy options:

- Messages in r0-r3 on ARM, optionally r12 descriptor. 16 byte message limit.
- Messages in r4-r11 on ARM, which the kernel needs to save anyhow. 32 byte
  message limit.

Let us assume that a message can include a reference to memory in the sender's
process consisting of a pointer and a length. Let's further assume that there
are R/W bits associated.

- If the R bit is set, the recipient can read the memory through kernel
  calls.
- And so with W.

Alternatively we could have the message passing interface deliver a copy of the
memory as a blob, but that seems less flexible.

Alternatively2 there could be two references, a R one to send with the message,
and a W one where a response can be received.

Alternatively 3 there could be *only those* a la QNX. Consider: we don't have
virtual memory, so memory accesses during message sends don't risk a page fault.
If the kernel is agreeing to run memcpy _anyway_ then why have two mechanisms?
Plus, messages are probably going to be structs anyway.

---

Messages need to be sent to a combination of (object ID, generation) so that
people won't try to carry on conversations with resurrections of entities.

---

Should have notifications.

- Fixed-size bitmask per task
- Plus a mask-mask
- On any receive, if bits in the notification set that are also in the mask set
  are set (whew) then that gets received in place of a message
- There should also be a directed receive to only get notifications

---

MINIX 3's asynchronous send primitive is worth further study.

Recall that messaging in MINIX is heavily restricted. Only system processes get
to use the full scheme.

So.

Issuing a SENDA (formerly ASEND) records the address and length of a table in
the sender's proc structure in the kernel. The kernel immediately processes
every entry in it by:

- Checking to see if the DONE flag is set (in which case it's ignored)
- Checking to see if the endpoint is valid
- Checking to see if the endpoint is blocked in receive
- If so, deliver message and mark as DONE.
- If not, *set an asynchronous pending flag on the recipient.*

The table is rescanned only on (1) repeated SENDA or (2) a receive by a process
with that asynchronous pending flag set.

There's only one flag per process, how does a process know *which* table to
scan? Well, that's easy: the kernel just scans *all of them.* Because only
"privileged" processes can use SENDA, there's only a tiny set of possible
culprits (~5), so nbd.

You could imagine extending the flag to a bitmask if this became troublesome.

SENDA is neat because:

- It allows for a process to have multiple outgoing asynchronous messages
  simultaneously without dynamic resource allocation *or* lots of kernel
  bookkeeping.

- It's just about the simplest thing that could work for that.

---

Studying MINIX 3's memory grant architecture.

Grant tables, like SENDA tables, are in the user address space. The program
informs the kernel of their existence using a syscall.

Each table entry designates an address range, rights bits, and the ID of the
grantee. They get checked on use: when the grantee wishes to access memory
through the grant, it performs a system call and names the *grantor* and the
grant number. The kernel checks that the grant's grantee field matches, and then
performs the access.

To support forwarding, MINIX 3 also allows for *indirect grants*. An indirect
grant names the grantee and has permissions, but it also names the *original
grantor* and the grant ID. It can specify an offset and size to forward a
*subset* of the grant. When the eventual recipient tries to use the grant, the
kernel finds the indirect grant and follows its link until it finds the original
direct grant.

I avoided this sort of thing for Brittle because

1. Forwarding grants requires resources in each forwarding process, which seemed
   a bit shit

2. That forwarding scheme implies a linear-time kernel operation, which is of
   course a no-no in Brittle.

This architecture is neat. It's different from supporting QNX-style arbitrary
length messages because accesses can happen after the sending message returns --
until the process revokes the grant. What on earth is that for? Is it even a
good idea?

I'm not presently convinced that I would need this.

---

Let's assume that messaging a *task* controls the task and messages need to go
through a *port.*

So how do you control a port then?

Sigh. Brittle's approach to this is better founded.

What am I trying to achieve.

- The ability to use MAC to prevent a task from rebooting others, for example
- Keep clients from receiving messages intended for servers.

Huh. Okay. Maybe all control messages go through an object-table-like object
that can be easily MAC'd off.

Maybe MAC has separate bits for send/receive.

---

# Concrete(ish) design 1

We have tasks.

Tasks can:

- Run code.
- Send messages to other tasks.
- Receive messages.

Task-to-task messages are filtered by a bitmask: imagine an NxN bit array. For
task N to send to task M, bit (N, M) must be set. A similar bitmask guards
receive. This is the world's simplest MAC framework.

There's also a set of _control_ operations, which include

- Starting a task from its initial suspended state
- Stopping a task
- Resetting a task
- Rebooting the system
- Messing with interrupts
- Possibly managing DMA

These operations are exposed as messages to a fake kernel task (or a small set
thereof). I would assume that the MAC filters would only allow certain tasks to
talk to these endpoints.

## The messaging operation

A "call" style message takes a `&[u8]` to send and a `&mut [u8]` into which to
receive. Call is subject to MAC filters.

A "receive" operation specifies a `&mut [u8]` for sent message to land in. If
the sent message is too large for the receive buffer, only part is delivered and
a flag is set where the recipient can see it. The recipient *may* be able to see
how large a response buffer the caller provided. Call is subject to MAC filters.

A "reply" operation is like the send half of a call, with the same behavior if
sizes don't match. Reply is not subject to filtering, but *does* check that the
target is actually waiting for a reply.

This means calls cannot be forwarded, though they can be chained.

Other operations we'd probably want are:

- Non-blocking send, perhaps, to best-effort deliver a message to a waiting
  task. This would be used downhill to lower priority tasks.

- Async send a la MINIX 3, which allows a task to have multiple outstanding
  messages to blocked recipients.

In addition to MAC filters it might be desirable to impose priority restrictions
on calls:

- Call must go uphill (or sideways).

- Directed receive must go downhill.

- Async send must go downhill.

## Missing pieces

### Mutex

The system as proposed includes no synchronization primitives. I would expect
these to be implemented in a high-priority task, which I'll call S.

- client C calls S with the `TakeMutex` operation code and a mutex ID.
- S checks if the mutex is free. If so, it is marked as taken by client C and
  S responds immediately.
- Otherwise, C is placed on the mutex's wait queue. C's priority is read, and
  compared to the priorities of other tasks in the queue; if it is higher, the
  mutex priority is updated, and the current holder H's priority is increased.

- holder H calls S with the `GiveMutex` operation code and a mutex ID.
- S checks that H holds the mutex; if not, this is an error.
- S replies to H.
- S finds the highest priority waiter W in the mutex's wait queue.
- The holder of the mutex is set to W.
- W's priority is, by definition, the highest waiter priority at this time, so
  no priority inheritance calculation needs to be performed.
- S replies to W's original `TakeMutex` operation.

In the description above there are a few pieces required:

1. S must be able to reliably name its callers.

2. S must maintain priority queues _in user memory._

3. S must be able to read the priorities of its callers.

4. S must be able to assign priorities to implement inheritance.

#### Timeouts

Okay, how about timeouts?

- Timeouts could be managed by S: it maintains an alarm queue and registers for
  a notification from the kernel at the next timeout. At each timeout it replies
  to the expiring caller with an error code. This has the advantage that
  everything is totally synchronous with respect to S.

- Timeouts could be part of the IPC: senders could give up while in the wait
  queue. S would need to take action in response to this, because if the highest
  priority waiter gives up, we need to update the mutex priority, so S needs to
  be able to detect this -- perhaps by a notification? Or a message from the
  kernel saying "task T has given up waiting for a reply from you."

I still don't love timeouts as a part of IPC so I'm inclined to go for the first
option.

#### Priority inheritance

Okay -- priority inheritance -- surely I have missed something.

Multiple mutexes may contribute to a task's priority if a task can hold multiple
mutexes. This doesn't affect the "new waiter, boost priority" algorithm, but
*does* affect timeouts / waiters leaving.

- When a task releases a mutex, we demote its priority to the highest priority
  among all mutexes it still holds.

- When a task gives up on a mutex, if that task was the only task in the highest
  pending priority level, we have to recompute the holder's eff priority based
  on the mutexes it still holds.

This can all go recursive, at a depth up to number-of-mutexes.

#### What about priority ceiling instead?

Priority ceiling protocol summary: or, actually, Highest Locker's Priority
protocol, which is a simplified PCP.

- Each mutex has an associated priority.

- Tasks can only lock mutexes with priorities higher than their _current
  effective priority._

- While a task holds mutexes, its priority is raised to the maximum of the
  priority levels of all held mutexes.
  - Because of the rule above, this means that no task that could contend for
    the mutex can be scheduled period.

- This also enforces mutex locking order to be in strict ascending priority.




### Queues

Queues live in a task S, so operations on queues are automatically synchronous
with respect to one another.

Push:

- Send message containing `Push` operation code and data item.
- Data item gets copied into S's receive area.
- S checks for space; if queue is full, caller could be told to piss off
  (nonblocking) or entered into a wait queue.
  - Note: we have to hold on to the received item while the caller waits, which
    means we need one additional receive buffer _per potential caller task._
- If anyone is waiting to pop (the queue is empty) the value is sent as a
  response to the popper, and we reply immediately.
- Otherwise, the item gets written into queue storage, and we resume the caller.

Pop:

- Send message containing `Pop` operation with response data area.
- S checks for contents; if the queue is empty, the caller is recorded on the
  wait queue.
- If the queue is not empty, one item is copied to the caller.
- If any task was waiting to push, its entry is copied from its holding buffer
  into the queue, and it is resumed.

Okay so this is exactly the sort of case where Minix3-style memory grants would
be useful. Here is a retooling of that scheme using memory grants.

Push:

- Set up memory grant to S describing item to push.
- Send message containing `Push` operation code
- S checks for space; if queue is full, caller could be told to piss off
  (nonblocking) or entered into a wait queue.
- Message gets read through the grant into S's address space. Caller gets
  resumed.
- If anyone is waiting to pop (the queue is empty) the message gets copied
  through that caller's grant into their address space, and we also resume them.

Pop:

- Set up memory grant ot S describing pop receive area.
- Send message containing `Pop` operation.
- S checks for contents; if the queue is empty, the caller is recorded on the
  wait queue.
- If the queue is not empty, one item is copied to the caller through their
  grant.
- If any task was waiting to push, its entry is copied through its grant into
  the queue, and it is resumed.

## System architecture sketches

### The Supervisor

The supervisor is an algorithm that runs in a high-priority task and is
responsible for monitoring the operation of other tasks.

The supervisor periodically sends a heartbeat/checkin message to monitored tasks
using async send. It continuously monitors replies. If the reply to the checkin
message does not arrive in a timely fashion, or does not make sense, the task is
considered to be malfunctioning and action can be taken.

- Supervisor-to-monitored messages use async send.
- Monitored-to-supervisor messages use nonblocking send.

### Data collection and aggregation

Implement a sensor data collection task that basically never blocks, just stores
stuff in RAM. Everyone calls it with confidence that it will be timely.

## Rust notes

Can memory grants be made safe?

Consider: while a memory grant is outstanding, the area of memory it references
is potentially accessed asynchronously. This is _probably_ OK for reads, though
updates to the area would need to be atomic. It's much trickier for writes.

Having the grant outstanding only for the duration of the call could work around
this: the callee borrows the grant area but the scope of the borrow is limited
by the kernel.

Basically, it's an interprocess borrow.

### Recasting IPC in Rust terms

IPC transfers by-value a block of memory, which can be parameters or return.

IPC can also transfer borrows. At least one. Maybe more than one?

Borrows are orchestrated as follows:

- Caller sets up a borrow descriptor table.
- Caller conveys it with the call somehow.
- Recipient gets information about the presence of borrows.
- Recipient has operations that can access said borrows.
- On reply, the kernel forgets that borrows happened, so they are reliably
  scoped.

A borrow descriptor can represent

- A borrow of a contiguous section of the caller's address space
- With read or write bits
- OR: an indirection to a caller's borrow, so that borrows can be passed.

Borrow types should _really_ be FFI-safe but the only _real_ requirement is that
they don't contain pointers, unless those pointers are also borrowed.

Borrows can only be copied out of or into, they cannot be mapped into memory
directly. (They technically _can_ but I'm avoiding that complexity.)

### by-value?

If we switch the IPC primitive to transferring like 8x registers, always, and
borrows optionally, then...

- (+) kernel only accesses user memory using grants. One checking path.
- (+) messaging fast path is fast, doesn't involve MPU checking
- (-) all Rust types can be represented in memory; not all types can be
  represented in registers. Would probably need an IDL to map enums/structs to
  registers.

This would be a useful kernel simplification at some cost in the user programs.

I'm not totally sure that's the right way to err.

---

How do grants interact with SENDA?

Concretely: user program calls "up" to system task. System task wants to forward
the request to a driver, but in a way that neither the user nor the system are
making a blocking call to the driver. And yet, we want the driver to get the
borrow. This means borrows need to be able to travel across SENDA.

And they need to be revocable.

If the process using SENDA can borrow local memory, as opposed to just
forwarding, then we have a potential for aliasing, because the lending task is
not suspended. This means the lender must be careful.

The borrow can be revoked by simply clearing its descriptor; any further uses of
such a borrow will hit an invalid descriptor and get rejected. So once we've
written that memory and issued a barrier, we're good. This could be done in the
lending process by a destructor on the borrow. Could also tie it to a RefCell in
the API (not the OS).


